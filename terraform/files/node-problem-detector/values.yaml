settings:
  # Custom monitor definitions to add to Node Problem Detector - to be
  # mounted at /custom-config. These are in addition to pre-packaged monitor
  # definitions provided within the default docker image available at /config:
  # https://github.com/kubernetes/node-problem-detector/tree/master/config
  # settings.custom_monitor_definitions -- Custom plugin monitor config files
  custom_monitor_definitions:
    oke-gpu-ecc.json: |
        {
        "plugin": "custom",
        "pluginConfig": {
            "invoke_interval": "300s",
            "timeout": "30s",
            "max_output_length": 80,
            "concurrency": 1,
            "enable_message_change_based_condition_update": true
        },
        "source": "oke-gpu-ecc.json",
        "metricsReporting": true,
        "conditions": [
            {
            "type": "GpuEcc",
            "reason": "GpuEccHasNoIssues",
            "message": "No ECC issues detected with GPUs"
            }
        ],
        "rules": [
            {
            "type": "permanent",
            "condition": "GpuEcc",
            "reason": "GpuEccHasIssues",
            "path": "./custom-config/oke_healthcheck.sh",
            "args": [ "ecc-err" ],
            "timeout": "30s"
            }
        ]
        }
    oke-gpu-remap.json: |
        {
        "plugin": "custom",
        "pluginConfig": {
            "invoke_interval": "300s",
            "timeout": "30s",
            "max_output_length": 80,
            "concurrency": 1,
            "enable_message_change_based_condition_update": true
        },
        "source": "oke-gpu-remap.json",
        "metricsReporting": true,
        "conditions": [
            {
            "type": "GpuRowRemap",
            "reason": "GpuRowRemapHasNoIssues",
            "message": "No Row Remapping issues detected with GPUs"
            }
        ],
        "rules": [
            {
            "type": "permanent",
            "condition": "GpuRowRemap",
            "reason": "GpuRowRemapHasIssues",
            "path": "./custom-config/oke_healthcheck.sh",
            "args": [ "rowremap-err" ],
            "timeout": "30s"
            }
        ]
        }

    oke-gpu-bus.json: |
        {
        "plugin": "custom",
        "pluginConfig": {
            "invoke_interval": "300s",
            "timeout": "30s",
            "max_output_length": 80,
            "concurrency": 1,
            "enable_message_change_based_condition_update": true
        },
        "source": "oke-gpu-bus.json",
        "metricsReporting": true,
        "conditions": [
            {
            "type": "GpuBus",
            "reason": "GpuBusHasNoIssues",
            "message": "No GPU Bus issues detected with GPUs"
            }
        ],
        "rules": [
            {
            "type": "permanent",
            "condition": "GpuBus",
            "reason": "GpuBusHasIssues",
            "path": "./custom-config/oke_healthcheck.sh",
            "args": [ "bus-stat" ],
            "timeout": "30s"
            }
        ]
        }

    oke-gpu-count.json: |
        {
        "plugin": "custom",
        "pluginConfig": {
            "invoke_interval": "300s",
            "timeout": "30s",
            "max_output_length": 80,
            "concurrency": 1,
            "enable_message_change_based_condition_update": true
        },
        "source": "oke-gpu-count.json",
        "metricsReporting": true,
        "conditions": [
            {
            "type": "GpuCount",
            "reason": "GpuCountHasNoIssues",
            "message": "Node has the expected number of GPUs"
            }
        ],
        "rules": [
            {
            "type": "permanent",
            "condition": "GpuCount",
            "reason": "GpuCountHasIssues",
            "path": "./custom-config/oke_healthcheck.sh",
            "args": [ "gpu-count" ],
            "timeout": "30s"
            }
        ]
                }

    oke-gpu-pcie.json: |
        {
        "plugin": "custom",
        "pluginConfig": {
            "invoke_interval": "300s",
            "timeout": "30s",
            "max_output_length": 80,
            "concurrency": 1,
            "enable_message_change_based_condition_update": true
        },
        "source": "oke-gpu-pcie.json",
        "metricsReporting": true,
        "conditions": [
            {
            "type": "GpuPcie",
            "reason": "GpuPcieHasNoIssues",
            "message": "Node has the expected PCIE bandwidth"
            }
        ],
        "rules": [
            {
            "type": "permanent",
            "condition": "GpuPcie",
            "reason": "GpuPcieHasIssues",
            "path": "./custom-config/oke_healthcheck.sh",
            "args": [ "gpu-pcie" ],
            "timeout": "30s"
            }
        ]
        }

    oke-gpu-fabric-mgr.json: |
        {
        "plugin": "custom",
        "pluginConfig": {
            "invoke_interval": "300s",
            "timeout": "30s",
            "max_output_length": 80,
            "concurrency": 1,
            "enable_message_change_based_condition_update": true
        },
        "source": "oke-gpu-fabric-mgr.json",
        "metricsReporting": true,
        "conditions": [
            {
            "type": "GpuFabricMgr",
            "reason": "GpuFabricMgrHasNoIssues",
            "message": "Fabric Manager is running"
            }
        ],
        "rules": [
            {
            "type": "permanent",
            "condition": "GpuFabricMgr",
            "reason": "GpuFabricMgrHasIssues",
            "path": "./custom-config/oke_healthcheck.sh",
            "args": [ "fabric-mgr" ],
            "timeout": "30s"
            }
        ]
        }

    oke-gpu-bad-pages.json: |
        {
        "plugin": "custom",
        "pluginConfig": {
            "invoke_interval": "300s",
            "timeout": "30s",
            "max_output_length": 80,
            "concurrency": 1,
            "enable_message_change_based_condition_update": true
        },
        "source": "oke-gpu-bad-pages.json",
        "metricsReporting": true,
        "conditions": [
            {
            "type": "GpuBadPages",
            "reason": "GpuBadPagesHasNoIssues",
            "message": "No GPU bad pages exists"
            }
        ],
        "rules": [
            {
            "type": "permanent",
            "condition": "GpuBadPages",
            "reason": "GpuBadPagesHasIssues",
            "path": "./custom-config/oke_healthcheck.sh",
            "args": [ "bad-page" ],
            "timeout": "30s"
            }
        ]
                }

    oke-rdma-link.json: |
        {
        "plugin": "custom",
        "pluginConfig": {
            "invoke_interval": "300s",
            "timeout": "30s",
            "max_output_length": 80,
            "concurrency": 1,
            "enable_message_change_based_condition_update": true
        },
        "source": "oke-rdma-link.json",
        "metricsReporting": true,
        "conditions": [
            {
            "type": "RdmaLink",
            "reason": "RdmaLinkHasNoIssues",
            "message": "All RDMA links are up"
            }
        ],
        "rules": [
            {
            "type": "permanent",
            "condition": "RdmaLink",
            "reason": "RdmaLinkHasIssues",
            "path": "./custom-config/oke_healthcheck.sh",
            "args": [ "rdmalink-stat" ],
            "timeout": "30s"
            }
        ]
                }

    oke-rdma-link-flapping.json: |
        {
        "plugin": "custom",
        "pluginConfig": {
            "invoke_interval": "300s",
            "timeout": "30s",
            "max_output_length": 80,
            "concurrency": 1,
            "enable_message_change_based_condition_update": true
        },
        "source": "oke-rdma-link-flapping.json",
        "metricsReporting": true,
        "conditions": [
            {
            "type": "RdmaLinkFlapping",
            "reason": "RdmaLinkFlappingHasNoIssues",
            "message": "No flapping RDMA links"
            }
        ],
        "rules": [
            {
            "type": "permanent",
            "condition": "RdmaLinkFlapping",
            "reason": "RdmaLinkFlappingHasIssues",
            "path": "./custom-config/oke_healthcheck.sh",
            "args": [ "rdmalink-flap" ],
            "timeout": "30s"
            }
        ]
                }

    oke-rdma-wpa-auth.json: |
        {
        "plugin": "custom",
        "pluginConfig": {
            "invoke_interval": "300s",
            "timeout": "30s",
            "max_output_length": 80,
            "concurrency": 1,
            "enable_message_change_based_condition_update": true
        },
        "source": "oke-rdma-wpa-auth.json",
        "metricsReporting": true,
        "conditions": [
            {
            "type": "RdmaWpaAuth",
            "reason": "RdmaWpaAuthHasNoIssues",
            "message": "All RDMA links are authenticated"
            }
        ],
        "rules": [
            {
            "type": "permanent",
            "condition": "RdmaWpaAuth",
            "reason": "RdmaWpaAuthHasIssues",
            "path": "./custom-config/oke_healthcheck.sh",
            "args": [ "wpa-auth" ],
            "timeout": "30s"
            }
        ]
                }

    oke-rdma-rttcc.json: |
        {
        "plugin": "custom",
        "pluginConfig": {
            "invoke_interval": "300s",
            "timeout": "30s",
            "max_output_length": 80,
            "concurrency": 1,
            "enable_message_change_based_condition_update": true
        },
        "source": "oke-rdma-rttcc.json",
        "metricsReporting": true,
        "conditions": [
            {
            "type": "RdmaRttcc",
            "reason": "RdmaRttccHasNoIssues",
            "message": "RTCCC is disabled on all RDMA interfaces"
            }
        ],
        "rules": [
            {
            "type": "permanent",
            "condition": "RdmaRttcc",
            "reason": "RdmaRttccHasIssues",
            "path": "./custom-config/oke_healthcheck.sh",
            "args": [ "rttcc-stat" ],
            "timeout": "30s"
            }
        ]
        }

    oke-oca-version.json: |
        {
        "plugin": "custom",
        "pluginConfig": {
            "invoke_interval": "300s",
            "timeout": "30s",
            "max_output_length": 80,
            "concurrency": 1,
            "enable_message_change_based_condition_update": true
        },
        "source": "oke-oca-version.json",
        "metricsReporting": true,
        "conditions": [
            {
            "type": "OcaVersion",
            "reason": "OcaVersionHasNoIssues",
            "message": "OCA version is up to date"
            }
        ],
        "rules": [
            {
            "type": "permanent",
            "condition": "OcaVersion",
            "reason": "OcaVersionHasIssues",
            "path": "./custom-config/oke_healthcheck.sh",
            "args": [ "oca-ver" ],
            "timeout": "30s"
            }
        ]
                }

    oke-cpu-profile.json: |
        {
        "plugin": "custom",
        "pluginConfig": {
            "invoke_interval": "300s",
            "timeout": "30s",
            "max_output_length": 80,
            "concurrency": 1,
            "enable_message_change_based_condition_update": true
        },
        "source": "oke-cpu-profile.json",
        "metricsReporting": true,
        "conditions": [
            {
            "type": "CpuProfile",
            "reason": "CpuProfileHasNoIssues",
            "message": "CPU profile is set to performance"
            }
        ],
        "rules": [
            {
            "type": "permanent",
            "condition": "CpuProfile",
            "reason": "CpuProfileHasIssues",
            "path": "./custom-config/oke_healthcheck.sh",
            "args": [ "cpu-profile" ],
            "timeout": "30s"
            }
        ]
        }

    oke-pcie-aer.json: |
        {
          "plugin": "filelog",
          "logPath": "/var/log/kern.log",
          "lookback": "5m",
          "bufferSize": 10,
          "source": "kernel",
          "metricsReporting": true,
          "conditions": [
            {
              "type": "NodeHasPcieErrors",
              "reason": "PcieAerError",
              "message": "Node has experienced PCIe AER errors"
            }
          ],
          "rules": [
            {
              "type": "permanent",
              "condition": "NodeHasPcieErrors",
              "reason": "PcieCorrectable",
              "pattern": ".*AER: Corrected error received.*"
            },
            {
              "type": "permanent",
              "condition": "NodeHasPcieErrors",
              "reason": "PcieNonFatal",
              "pattern": ".*AER: Non-Fatal error received.*"
            },
            {
              "type": "permanent",
              "condition": "NodeHasPcieErrors",
              "reason": "PcieFatal",
              "pattern": ".*AER: Fatal error received.*"
            }
          ]
        }


    oke_healthcheck.sh: |
        #!/bin/bash

        readonly OK=0
        readonly NONOK=1
        readonly UNKNOWN=2

        healthcheck_type=$1
        healtcheck_log_file=/host/tmp/oke-latest-${healthcheck_type}-healthcheck.log

        cp ./config/*.py /host/tmp

        chroot /host bash -c "chmod +x /tmp/check_gpu_setup.py"
        chroot /host bash -c "/tmp/check_gpu_setup.py --slurm --$healthcheck_type > /tmp/oke-latest-${healthcheck_type}-healthcheck.log 2>&1"

        ERROR_MSG=$(cat "$healtcheck_log_file" | grep "Healthcheck::")
        UNKNOWN_MSG=$(cat "$healtcheck_log_file" | grep -o 'Skipping.*')

        if [ "$ERROR_MSG" != "" ]
        then
            echo "${ERROR_MSG#* }"
            exit $NONOK
        elif [ "$ERROR_MSG" == "" ] && [ "$UNKNOWN_MSG" != "" ]
        then
            echo $UNKNOWN_MSG
            exit $UNKNOWN
        else
            echo "No errors found"
            exit $OK
        fi
        

  log_monitors:
    - /config/kernel-monitor.json
    - /config/docker-monitor.json
    - /config/readonly-monitor.json
    - /custom-config/oke-pcie-aer.json
    # An example of activating a custom log monitor definition in
    # Node Problem Detector
    # - /custom-config/docker-monitor-filelog.json
  custom_plugin_monitors:
    - /custom-config/oke-gpu-ecc.json
    - /custom-config/oke-gpu-remap.json
    - /custom-config/oke-gpu-bus.json
    - /custom-config/oke-gpu-count.json
    - /custom-config/oke-rdma-link.json
    - /custom-config/oke-rdma-link-flapping.json
    - /custom-config/oke-rdma-wpa-auth.json
    - /custom-config/oke-rdma-rttcc.json
    - /custom-config/oke-oca-version.json
    - /custom-config/oke-gpu-pcie.json
    - /custom-config/oke-gpu-fabric-mgr.json
    - /custom-config/oke-gpu-bad-pages.json
    - /custom-config/oke-cpu-profile.json

  # Any extra arguments to append to node-problem-detector command
  # - "--port 20526"
  extraArgs: []

  # settings.prometheus_address -- Prometheus exporter address
  prometheus_address: 0.0.0.0
  # settings.prometheus_port -- Prometheus exporter port
  prometheus_port: 20257

  # The period at which k8s-exporter does forcibly sync with apiserver
  # settings.heartBeatPeriod -- Syncing interval with API server
  heartBeatPeriod: 5m0s

logDir:
  # logDir.host -- log directory on k8s host
  host: /var/log/
  # logDir.pod -- log directory in pod (volume mount), use logDir.host if empty
  pod: ""

image:
  repository: iad.ocir.io/idxzjcdglx2s/oke-npd
  tag: v1.34.0-1
  # image.digest -- the image digest. If given it takes precedence over a given tag.
  digest: ""
  pullPolicy: IfNotPresent

imagePullSecrets: []

nameOverride: ""
fullnameOverride: "gpu-rdma-node-problem-detector"

rbac:
  create: true
  pspEnabled: false

# hostNetwork -- Run pod on host network
# Flag to run Node Problem Detector on the host's network. This is typically
# not recommended, but may be useful for certain use cases.
hostNetwork: false
hostPID: false

volume:
  localtime:
    type: "FileOrCreate"

priorityClassName: system-node-critical

securityContext:
  privileged: true

resources: {}

annotations: {}

labels: {}

tolerations:
  - effect: NoSchedule
    operator: Exists

serviceAccount:
  # Specifies whether a ServiceAccount should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # Labels to add to the service account
  labels: {}
  # The name of the ServiceAccount to use.
  # If not set and create is true, a name is generated using the fullname template
  name:

affinity:
  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
        - matchExpressions:
            - key: node.kubernetes.io/instance-type
              operator: In
              values:
              - BM.GPU.A100-v2.8
              - BM.GPU.B4.8
              - BM.GPU4.8
              - BM.GPU.H100.8
              - BM.GPU.MI300X.8
              - BM.GPU.L40S-NC.4
              - BM.GPU.A10.4
              - VM.GPU.A10.1
              - VM.GPU.A10.2
              - VM.GPU.A100.80G.1
              - BM.GPU.H200.8
              - BM.GPU.B200.8
              - BM.GPU.GB200.4
              - BM.GPU.GB200-v2.4

nodeSelector: {}

metrics:
  # metrics.enabled -- Expose metrics in Prometheus format with default configuration.
  enabled: true
  # metrics.annotations -- Override all default annotations when `metrics.enabled=true` with specified values.
  annotations: {}
  serviceMonitor:
    enabled: true
    attachMetadata:
      node: true
    additionalLabels:
      release: kube-prometheus-stack
    additionalRelabelings:
      - sourceLabels: [__meta_kubernetes_node_provider_id]
        targetLabel: instance_id
        action: replace
      - sourceLabels: [__meta_kubernetes_node_label_oci_oraclecloud_com_host_serial_number]
        targetLabel: host_serial_number
        action: replace
      - sourceLabels: [__meta_kubernetes_node_label_node_kubernetes_io_instance_type]
        targetLabel: instance_shape
        action: replace
      - sourceLabels: [__meta_kubernetes_node_label_displayName]
        targetLabel: oci_name
        action: replace
      - sourceLabels: [__meta_kubernetes_node_label_oke_oraclecloud_com_pool_name]
        targetLabel: worker_pool_name
        action: replace
      - sourceLabels: [__meta_kubernetes_node_label_oke_oraclecloud_com_cluster_name]
        targetLabel: cluster_name
        action: replace
      - sourceLabels: [__meta_kubernetes_pod_node_name]
        targetLabel: hostname
        action: replace
    metricRelabelings: []
  prometheusRule:
    enabled: false
    defaultRules:
      create: false
      disabled: []
    additionalLabels:
      release: kube-prometheus-stack
    additionalRules: []

extraVolumes:
  - name: root
    hostPath:
      path: /

extraVolumeMounts:
  - name: root
    mountPath: /host

extraContainers: []

# updateStrategy -- Manage the daemonset update strategy
updateStrategy: RollingUpdate
# maxUnavailable -- The max pods unavailable during an update
maxUnavailable: 1